{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fd4a50",
   "metadata": {},
   "source": [
    "# Process image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "folder = './faces'\n",
    "\n",
    "print(folder)\n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    # Asume imágenes en formato png o jpg\n",
    "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "        # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "        obj = DeepFace.analyze(img_path = os.path.join(folder, file_name), enforce_detection=False, actions =['age', 'gender', 'race', 'emotion'])\n",
    "        print(file_name)\n",
    "        print(obj)\n",
    "        #print(obj[\"region\"])\n",
    "        #print(obj[\"age\"])      \n",
    "        #print(obj[\"gender\"])      \n",
    "        #print(obj[\"race\"])       \n",
    "        #print(obj[\"dominant_race\"]) \n",
    "        #print(obj[\"emotion\"])\n",
    "        #print(obj[\"dominant_emotion\"])\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643c68d5",
   "metadata": {},
   "source": [
    "# Process from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1843aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n",
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 10.315848886966705, 'Man': 89.68415260314941}, 'dominant_gender': 'Man', 'region': {'x': 409, 'y': 214, 'w': 30, 'h': 30}, 'emotion': {'angry': 0.011517193301907156, 'disgust': 8.79366520945702e-08, 'fear': 0.28018547960731266, 'happy': 0.6127656802693415, 'sad': 3.519238741352483, 'surprise': 0.00019090285833136452, 'neutral': 95.57610127783425}, 'dominant_emotion': 'neutral'}, {'gender': {'Woman': 0.05199472652748227, 'Man': 99.94800686836243}, 'dominant_gender': 'Man', 'region': {'x': 288, 'y': 174, 'w': 132, 'h': 132}, 'emotion': {'angry': 0.5580928642302752, 'disgust': 2.973695814034727e-05, 'fear': 7.687145471572876, 'happy': 1.011265441775322, 'sad': 3.107733279466629, 'surprise': 12.604521214962006, 'neutral': 75.0312089920044}, 'dominant_emotion': 'neutral'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.1437614904716611, 'Man': 99.85623955726624}, 'dominant_gender': 'Man', 'region': {'x': 286, 'y': 172, 'w': 131, 'h': 131}, 'emotion': {'angry': 3.059199448478189, 'disgust': 0.0030354480249399074, 'fear': 21.742129131682464, 'happy': 1.6287905203575206, 'sad': 55.41007252991632, 'surprise': 10.8327276010947, 'neutral': 7.324048568251643}, 'dominant_emotion': 'sad'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.03307967272121459, 'Man': 99.96691942214966}, 'dominant_gender': 'Man', 'region': {'x': 293, 'y': 174, 'w': 126, 'h': 126}, 'emotion': {'angry': 6.005258843616178, 'disgust': 0.009236191367838762, 'fear': 38.96766239211931, 'happy': 0.6480364980868398, 'sad': 7.038928242857947, 'surprise': 34.74708108586556, 'neutral': 12.583798920142586}, 'dominant_emotion': 'fear'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.16035556327551603, 'Man': 99.83964562416077}, 'dominant_gender': 'Man', 'region': {'x': 297, 'y': 172, 'w': 124, 'h': 124}, 'emotion': {'angry': 1.6367984935641289, 'disgust': 0.0003595808948375634, 'fear': 12.185833603143692, 'happy': 0.3599500982090831, 'sad': 52.76837348937988, 'surprise': 3.2270442694425583, 'neutral': 29.821640253067017}, 'dominant_emotion': 'sad'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.1449773903004825, 'Man': 99.85502362251282}, 'dominant_gender': 'Man', 'region': {'x': 296, 'y': 175, 'w': 123, 'h': 123}, 'emotion': {'angry': 0.6291098427027464, 'disgust': 0.0007683724106755108, 'fear': 1.2574429623782635, 'happy': 0.07466526003554463, 'sad': 33.506181836128235, 'surprise': 0.03688089200295508, 'neutral': 64.49494957923889}, 'dominant_emotion': 'neutral'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.051650829846039414, 'Man': 99.94834661483765}, 'dominant_gender': 'Man', 'region': {'x': 266, 'y': 180, 'w': 146, 'h': 146}, 'emotion': {'angry': 0.028975005261600018, 'disgust': 1.4195543178441294e-09, 'fear': 0.15804781578481197, 'happy': 0.0011017768883903045, 'sad': 3.2474584877490997, 'surprise': 0.0011805829672084656, 'neutral': 96.56323790550232}, 'dominant_emotion': 'neutral'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]\n",
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 16.58492684364319, 'Man': 83.41506719589233}, 'dominant_gender': 'Man', 'region': {'x': 401, 'y': 223, 'w': 33, 'h': 33}, 'emotion': {'angry': 0.1140893786214292, 'disgust': 1.082800782370441e-06, 'fear': 1.1170065961778164, 'happy': 5.810323730111122, 'sad': 2.1679824218153954, 'surprise': 0.004927469490212388, 'neutral': 90.78567028045654}, 'dominant_emotion': 'neutral'}, {'gender': {'Woman': 0.04945699474774301, 'Man': 99.95054006576538}, 'dominant_gender': 'Man', 'region': {'x': 272, 'y': 180, 'w': 138, 'h': 138}, 'emotion': {'angry': 1.940932497382164, 'disgust': 0.04030265554320067, 'fear': 68.4307336807251, 'happy': 0.11188708012923598, 'sad': 0.04923510714434087, 'surprise': 29.392054677009583, 'neutral': 0.03485544875729829}, 'dominant_emotion': 'fear'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.98it/s]\n",
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 9.41184014081955, 'Man': 90.58815240859985}, 'dominant_gender': 'Man', 'region': {'x': 401, 'y': 220, 'w': 33, 'h': 33}, 'emotion': {'angry': 0.17616444965824485, 'disgust': 5.457113729789853e-05, 'fear': 1.3845429755747318, 'happy': 29.304027557373047, 'sad': 2.8662964701652527, 'surprise': 0.05419040098786354, 'neutral': 66.21472239494324}, 'dominant_emotion': 'neutral'}, {'gender': {'Woman': 0.10946941329166293, 'Man': 99.89053010940552}, 'dominant_gender': 'Man', 'region': {'x': 272, 'y': 178, 'w': 134, 'h': 134}, 'emotion': {'angry': 0.7964170081267957, 'disgust': 0.014876927320960302, 'fear': 78.91950481650262, 'happy': 0.31974699391406736, 'sad': 0.026751861290185825, 'surprise': 19.921649689772707, 'neutral': 0.001050841882595681}, 'dominant_emotion': 'fear'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 2/2 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': {'Woman': 0.10523780947551131, 'Man': 99.89476799964905}, 'dominant_gender': 'Man', 'region': {'x': 277, 'y': 172, 'w': 137, 'h': 137}, 'emotion': {'angry': 9.299793648707489, 'disgust': 0.012752699727353437, 'fear': 50.30582847033909, 'happy': 1.80933858807913, 'sad': 33.28894277149098, 'surprise': 2.6965945703741654, 'neutral': 2.586746556266937}, 'dominant_emotion': 'fear'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from playsound import playsound\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# font \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2 \n",
    "pos = (50, 50) \n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, frame = vid.read()\n",
    "  \n",
    "    if ret:  \n",
    "        obj = DeepFace.analyze(img_path = frame, enforce_detection=False, actions =['gender', 'emotion'])\n",
    "        print(obj)\n",
    "\n",
    "        # Primera cara\n",
    "        image = cv2.putText(frame, str(obj[0]['dominant_gender']+' '+obj[0]['dominant_emotion']), pos, font,  \n",
    "                        fontScale, color, thickness, cv2.LINE_AA) \n",
    "        \n",
    "        match obj[0]['dominant_emotion']: \n",
    "            \n",
    "            case 'happy':\n",
    "\n",
    "                imghsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "\n",
    "                (h, s, v) = cv2.split(imghsv)\n",
    "                s = s*2\n",
    "                s = np.clip(s,0,255)\n",
    "                imghsv = cv2.merge([h,s,v])\n",
    "\n",
    "                frame = cv2.cvtColor(imghsv.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "            \n",
    "            case 'sad':\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "            case 'angry':\n",
    "\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.zeros((image.shape), dtype = np.uint8)\n",
    "                image[:,:,2] = frame\n",
    "                frame = image\n",
    "\n",
    "            case 'fear':\n",
    "                pass\n",
    "\n",
    "            case 'disgust':\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.zeros((image.shape), dtype = np.uint8)\n",
    "                image[:,:,1] = frame\n",
    "                frame = image\n",
    "                pass\n",
    "\n",
    "            case 'surprise':\n",
    "                pass\n",
    "\n",
    "            case 'neutral':\n",
    "                # playsound('./assets/sad_sound.mp3')\n",
    "\n",
    "                alpha = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "                cv2.ellipse(alpha, (int(image.shape[1] / 2), int(image.shape[0] / 2)), (300, 200), 0, 0, 360, (255, 255, 255), -1)\n",
    "                \n",
    "\n",
    "                image = cv2.bitwise_and(image, image, mask=alpha)\n",
    "                frame=image\n",
    "                pass\n",
    "                \n",
    "            case _:\n",
    "                pass\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', frame)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
