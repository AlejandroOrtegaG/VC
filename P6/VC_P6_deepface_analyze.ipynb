{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fd4a50",
   "metadata": {},
   "source": [
    "# Process image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "folder = './faces'\n",
    "\n",
    "print(folder)\n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    # Asume imágenes en formato png o jpg\n",
    "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "        # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "        obj = DeepFace.analyze(img_path = os.path.join(folder, file_name), enforce_detection=False, actions =['age', 'gender', 'race', 'emotion'])\n",
    "        print(file_name)\n",
    "        print(obj)\n",
    "        #print(obj[\"region\"])\n",
    "        #print(obj[\"age\"])      \n",
    "        #print(obj[\"gender\"])      \n",
    "        #print(obj[\"race\"])       \n",
    "        #print(obj[\"dominant_race\"]) \n",
    "        #print(obj[\"emotion\"])\n",
    "        #print(obj[\"dominant_emotion\"])\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643c68d5",
   "metadata": {},
   "source": [
    "# Process from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1843aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@191.880] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@191.881] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "#from playsound import playsound\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# font \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2 \n",
    "pos = (50, 50)\n",
    "\n",
    "def blend(input_rgb, alpha, rgb, coord: (int, int)):\n",
    "    cut = input_rgb[coord[1]:coord[1]+rgb.shape[0], coord[0]:coord[0]+rgb.shape[1]].astype(\"float32\")\n",
    "\n",
    "    # Multiply the foreground with the alpha matte\n",
    "    rgb = cv2.multiply(cv2.cvtColor(alpha, cv2.COLOR_GRAY2BGR), rgb)\n",
    "    cut = cv2.multiply(cv2.cvtColor(1.0 - alpha, cv2.COLOR_GRAY2BGR), cut)\n",
    "\n",
    "    # Add the masked foreground and background\n",
    "\n",
    "    input_rgb[coord[1]:coord[1]+rgb.shape[0], coord[0]:coord[0]+rgb.shape[1]] = cv2.add(rgb, cut).astype(\"uint8\")\n",
    "    return input_rgb\n",
    "\n",
    "def read_transparent_png(filename):\n",
    "    image_4channel = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    alpha_channel = image_4channel[:,:,3].astype(\"float32\") / 255\n",
    "    rgb_channels = image_4channel[:,:,:3].astype(\"float32\")\n",
    "    return (alpha_channel, rgb_channels)\n",
    "\n",
    "balloons = read_transparent_png(\"assets/balloons.png\")\n",
    "confetti = read_transparent_png(\"assets/confetti.png\")\n",
    "rain = read_transparent_png(\"assets/rain.png\")\n",
    "sangre1 = read_transparent_png(\"assets/sangre1.png\")\n",
    "serious = read_transparent_png(\"assets/serious.png\")\n",
    "vignette = read_transparent_png(\"assets/vignette.png\")\n",
    "stars = read_transparent_png(\"assets/stars.png\")\n",
    "\n",
    "while(True):\n",
    "    # fotograma a fotograma\n",
    "    ret, frame = vid.read()\n",
    "  \n",
    "    if ret:  \n",
    "        obj = DeepFace.analyze(img_path = frame, enforce_detection=False, actions =['gender', 'emotion'])\n",
    "        print(obj[0]['dominant_emotion'])\n",
    "        # Primera cara\n",
    "        #image = cv2.putText(frame, str(obj[0]['dominant_gender']+' '+obj[0]['dominant_emotion']), pos, font,  \n",
    "        #                fontScale, color, thickness, cv2.LINE_AA) \n",
    "        \n",
    "        match obj[0]['dominant_emotion']: \n",
    "            case 'happy':\n",
    "                imghsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "\n",
    "                (h, s, v) = cv2.split(imghsv)\n",
    "                s = s*2\n",
    "                s = np.clip(s,0,255)\n",
    "                imghsv = cv2.merge([h,s,v])\n",
    "\n",
    "                frame = cv2.cvtColor(imghsv.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "                frame = blend(frame, balloons[0], balloons[1], (0, 0))\n",
    "                frame = blend(frame, stars[0], stars[1], (0, 0))\n",
    "            \n",
    "            case 'sad':\n",
    "                frame = blend(frame, rain[0], rain[1], (0, 0))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "            case 'angry':\n",
    "                frame2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.zeros((frame.shape), dtype = np.uint8)\n",
    "                image[:,:,2] = frame2\n",
    "                frame = image\n",
    "\n",
    "            case 'fear':\n",
    "                imghsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "\n",
    "                (h, s, v) = cv2.split(imghsv)\n",
    "                s = 0.5*s\n",
    "                s = np.clip(s,0,255)\n",
    "                imghsv = cv2.merge([h,s,v])\n",
    "                frame = cv2.cvtColor(imghsv.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "                frame = blend(frame, vignette[0], vignette[1], (0, 0))\n",
    "                pass\n",
    "\n",
    "            case 'disgust':\n",
    "                frame2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.zeros((frame.shape), dtype = np.uint8)\n",
    "                image[:,:,1] = frame2\n",
    "                frame = image\n",
    "\n",
    "            case 'surprise':\n",
    "                frame = blend(frame, confetti[0], confetti[1], (0, 0))\n",
    "                frame = blend(frame, stars[0], stars[1], (0, 0))\n",
    "\n",
    "            case 'neutral':\n",
    "                frame = blend(frame, serious[0], serious[1], (0, 0))\n",
    "                pass\n",
    "                \n",
    "            case _:\n",
    "                pass\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', frame)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
